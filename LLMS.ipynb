{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d733522-b896-4337-b918-ff26fa20c98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jai Maa Kali_/\\_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\_'\n",
      "C:\\Users\\barad\\AppData\\Local\\Temp\\ipykernel_12700\\2338759233.py:1: SyntaxWarning: invalid escape sequence '\\_'\n",
      "  print('Jai Maa Kali_/\\_')\n"
     ]
    }
   ],
   "source": [
    "print('Jai Maa Kali_/\\_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4974df8-510f-411e-9810-43cbe344b629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b88985d-e5f7-4d41-9f33-67c6d4db293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ff89e30-b0b6-48f7-aff4-8a437c2f5c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.get('https://nreganarep.nic.in/netnrega/state_html/jcr.aspx?reg_no=AP-03-032-001-001/010006&village_code=0203032001001&fin_year=2023-2024&Digest=6lDVLtULeHcw4Ej+KoH15Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3a5291d-63bc-485b-be9d-e99445fd9af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import quote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3ebbe88-0d49-47b4-98eb-b3b4090d9b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://nreganarep.nic.in/netnrega/state_html/jcr.aspx?reg_no=AP-03-032-001-001/010006&village_code=0203032001001&fin_year=2023-2024&Digest=6lDVLtULeHcw4Ej+KoH15Q'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ffbb664-9533-44e0-bb76-f3d0f0b8904b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://nreganarep.nic.in/netnrega/state_html/jcr.aspx?reg_no=AP-03-032-001-001/010006&village_code=0203032001001&fin_year=2023-2024&Digest=6lDVLtULeHcw4Ej+KoH15Q?reg_no=AP-03-032-001-001%2F010006&village_code=0203032001001&fin_year=2023-2024&Digest=6lDVLtULeHcw4Ej%2BKoH15Q\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import quote\n",
    "\n",
    "base_url='https://nreganarep.nic.in/netnrega/state_html/jcr.aspx?reg_no=AP-03-032-001-001/010006&village_code=0203032001001&fin_year=2023-2024&Digest=6lDVLtULeHcw4Ej+KoH15Q'\n",
    "params = \"reg_no=AP-03-032-001-001/010006&village_code=0203032001001&fin_year=2023-2024&Digest=6lDVLtULeHcw4Ej+KoH15Q\"\n",
    "encoded_url = f\"{base_url}?{quote(params, safe='=&')}\"\n",
    "print(encoded_url)  # Verify this URL\n",
    "d.get(encoded_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef0df838-0c8c-4421-baa5-4903767ecac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jai Maa Kali_/\\_\n"
     ]
    }
   ],
   "source": [
    "print('Jai Maa Kali_/\\_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f0e7a3a-48d7-4985-9e87-32ee08e3cc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b475041-daf1-49dc-b44b-f78f1be2b1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fe6c597-a9e8-4b4c-8d32-f2a7cdbb237f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAI MAA KALI_/\\_\n"
     ]
    }
   ],
   "source": [
    "print('JAI MAA KALI_/\\_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98ba30a3-2c88-4029-a9dc-d140f00024e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#torch is used for building ,training and deploying pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "045eeafb-1a71-4c3b-b496-e3bdb30c47bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(seed=42):\n",
    "    torch.manual_seed(seed)#sets the random seed for CPU operations\n",
    "    torch.cuda.manual_seed(seed)#sets the random seed for GPU operations\n",
    "    torch.backends.cudnn.deterministic = True#Gpus operations are deterministic i.e same results will come,even runned many times\n",
    "    torch.backends.cudnn.benchmark = False#for True it takes fastest converging algorithm,for False takes best ,optimized algorithms\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b31c95f-fac8-45bd-b0c9-15811ab34ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b52399ec-f24a-4c18-a9c9-25ec5524524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base line model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b631d464-9fbd-490b-a14f-f086a5e720ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95350228-220b-4571-aaf9-fe2351ca53ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0338eb9e-28e8-411d-bcd9-8e83fcd1bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"upstage/TinySolar-248m-4k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ff76e85-ee4e-45e2-b03a-7ca202759b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='upstage/TinySolar-248m-4k', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aea112b7-2625-4105-888b-27019e1774c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"upstage/TinySolar-248m-4k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07908785-68cd-4782-a3e4-b1950e722af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (k_proj): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (v_proj): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (up_proj): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (down_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((1024,), eps=1e-06)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((1024,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((1024,), eps=1e-06)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "daae2573-d893-4c9f-b96d-ebac6181ea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"I am an engineer. I love\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "301942e5-bdec-4f64-bac7-eca0ef85c248",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=tokenizer(prompt,return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72069e5a-2d24-43d9-b044-05599e1d5dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer#Text Streamer helps to see output line by line or word by word,helps to stream the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "77864110-53fc-4b12-8468-c96114427eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1,   315,   837,   396, 18112, 28723,   315,  2016]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66c42756-37ad-4286-9860-c87f2db01e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=TextStreamer(\n",
    "    tokenizer,\n",
    "    skip_prompt=False,# input prompt will be skipped for True\n",
    "    skip_special_tokens=True# special tokens will be skipped\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4887c3e-982b-4b47-8bb8-5be589bb7af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.generation.streamers.TextStreamer at 0x2005ad9ffb0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19adb06c-68af-4c07-8b86-1ce2c798752c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am an engineer. I love to travel and have been a part of the community since 1985.\n",
      "I'm a big fan of the music scene in New York City, so I was excited to see what the city could do with this new album. The first track on the album is \"The Last Song\" which features the band's lead singer, guitarist, and bassist, John Lennon. It's a great song that will make you want to dance along to it all day long.\n",
      "The second track on the album is \"Song for the Night\" which features the band's lead vocalist, Paul\n"
     ]
    }
   ],
   "source": [
    "outputs=model.generate(**inputs, #** unpacks ids,masks\n",
    "    streamer=s, \n",
    "    use_cache=True,\n",
    "    max_new_tokens=128,#total length of output\n",
    "    do_sample=False, \n",
    "    temperature=0.0,\n",
    "    repetition_penalty=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99249fcd-d7f8-4449-bec3-7f45907cab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt =  \"def find_max(numbers):\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7582240-92df-480d-99cf-6df79ec56ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained(\"upstage/TinySolar-248m-4k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc5d386f-7aa7-4237-950b-528e79452005",
   "metadata": {},
   "outputs": [],
   "source": [
    "m= AutoModelForCausalLM.from_pretrained(path,device_map='cpu',torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5b86be72-074c-4fc9-b387-97fa4fd936a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    }
   ],
   "source": [
    "import accelerate\n",
    "print(accelerate.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66060c7f-79dc-4020-837f-a7bb99f475a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"upstage/TinySolar-248m-4k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94afb0c0-472d-485f-9fe6-dd9bf72465cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=tokenizer(prompt,return_tensors=\"pt\").to(m.device)# is used to move the tensors to that specific device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33a5a9a0-41a8-41f7-8f77-daf2a5cce7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1,   801,  1300, 28730,  2416, 28732,  2575,  1891,  1329]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5b554c9-ab90-4739-b787-3a19d622e0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=TextStreamer(tokenizer,skip_prompt=False,skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3de63e64-14b6-46f2-9a51-c23bfc0c4645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b120026e-6f6e-432a-b7a0-8420c9eb3a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def find_max(numbers):\n",
      "       \"\"\"\n",
      "       Returns the number of times a user has been added to the list.\n",
      "       \"\"\"\n",
      "       return num_users() + 1\n",
      "\n",
      "   def get_user_id(self, id):\n",
      "       \"\"\"\n",
      "       Returns the number of users that have been added to the list.\n",
      "       \"\"\"\n",
      "       return len(self.get_users())\n",
      "\n",
      "   def get_user_name(self, name):\n",
      "       \"\"\"\n",
      "       Returns the name of the user that has been added to the list.\n",
      "       \"\"\"\n",
      "       return self.get_user_name(name)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ouputs=m.generate(**inputs, \n",
    "    streamer=s, \n",
    "    use_cache=True, \n",
    "    max_new_tokens=128, \n",
    "    do_sample=False, \n",
    "    temperature=0.0, \n",
    "    repetition_penalty=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70590c4e-12ab-4e6a-bddb-e048f91fcc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c8edbec00234bae9f0ce613cc2e3526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/966 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efff25b2c1f14c3c873405ae647701c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90bdcbec696406193f6fd516200f4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b307d4e701b4497c911f4c227f50aefb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "067281d46b4849ad9f2e2f569a486d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/639 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3aa2c5188754f47ac0b6c4a2baec625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b579643c94434e028ea836c4cc8ab837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"upstage/TinySolar-248m-4k-py\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"upstage/TinySolar-248m-4k-py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67207a0b-dce0-4ab5-a7e2-5f732c664612",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"upstage/TinySolar-248m-4k-py\",device_map='cpu',torch_dtype=torch.bfloat16, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0347ee28-7a72-4e1d-94ea-ac8172c42d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer= AutoTokenizer.from_pretrained(\"upstage/TinySolar-248m-4k-py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a20e5cc-0503-4f24-9d05-7ef27f5b8c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"def find_max(numbers):\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4c0ed3e-7936-4b12-bbcb-cd0b855ae9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=tokenizer(prompt,return_tensors=\"pt\").to(m.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9dcd624d-2279-4df9-88c0-3ec6930a4479",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=TextStreamer(tokenizer,skip_prompt=True, \n",
    "    skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d02db51-a967-428b-ab57-f92d539f2206",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   \"\"\"Find the maximum number of numbers in a list.\"\"\"\n",
      "   max = 0\n",
      "   for num in numbers:\n",
      "       if num > max:\n",
      "           max = num\n",
      "   return max\n",
      "\n",
      "\n",
      "def get_min_max(numbers, min_value=1):\n",
      "   \"\"\"Get the minimum value of a list.\"\"\"\n",
      "   min_value = min_value or 1\n",
      "   for num in numbers:\n",
      "       if num < min_value:\n",
      "           min_value = num\n",
      "   return min_value\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(\n",
    "    **inputs, streamer=s,\n",
    "    use_cache=True, \n",
    "    max_new_tokens=128, \n",
    "    do_sample=False, \n",
    "    repetition_penalty=1.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f5cff83-15ca-4888-be13-7c971b7c7e13",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (1852295953.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[33], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    return max\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#   \"\"\"Find the maximum number of numbers in a list.\"\"\"\n",
    "max = 0\n",
    "for num in numbers:\n",
    "    if num > max:\n",
    "        max = num\n",
    "    return max\n",
    "\n",
    "\n",
    "def get_min_max(numbers, min_value=1):\n",
    "   \"\"\"Get the minimum value of a list.\"\"\"\n",
    "   m#in_value = min_value or 1\n",
    "   for num in numbers:\n",
    "       if num < min_value:\n",
    "           min_value = num\n",
    "   return min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "285eb9bf-2f34-4a90-bf0f-e078e6d2e54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_max(numbers, min_value=1):\n",
    "   \"\"\"Get the minimum value of a list.\"\"\"\n",
    "  # min_value = min_value or 1\n",
    "   for num in numbers:\n",
    "       if num < min_value:\n",
    "           min_value = num\n",
    "   return min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1a786f7-b571-4c6b-85bc-caf49fe1b31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max(numbers):\n",
    "   max = 1\n",
    "   for num in numbers:\n",
    "       if num < max:\n",
    "           max = num\n",
    "   return max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dfeac701-60ae-4b02-b73f-ab1310775d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_max([11,2,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f6677ec-2daf-450c-8931-9803ab298211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jai Maa Kali_/\\_\n"
     ]
    }
   ],
   "source": [
    "print('Jai Maa Kali_/\\_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293d9809-3ab7-4d09-9938-baf8f6181677",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
